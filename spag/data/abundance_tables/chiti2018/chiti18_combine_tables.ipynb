{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Python Packages & Directories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The matrix_product function is deprecated and may be removed in a future version.\n",
      "        Use @ instead. [gala.coordinates.sgr]\n",
      "WARNING: AstropyDeprecationWarning: The matrix_product function is deprecated and may be removed in a future version.\n",
      "        Use @ instead. [gala.coordinates.orphan]\n",
      "WARNING: AstropyDeprecationWarning: The matrix_product function is deprecated and may be removed in a future version.\n",
      "        Use @ instead. [gala.coordinates.magellanic_stream]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import (division, print_function, absolute_import,\n",
    "                        unicode_literals)\n",
    "import  sys, os, glob, time, IPython\n",
    "\n",
    "import astropy.constants as const\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "# from astropy.table import Table\n",
    "# from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "\n",
    "# from PyAstronomy import pyasl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# from smh import Session\n",
    "\n",
    "import spag.read_data as rd\n",
    "import spag.coordinates as coord\n",
    "# import alexmods.read_data as rd\n",
    "\n",
    "\n",
    "script_dir = \"/\".join(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]) + \"/\"\n",
    "# script_dir = os.path.dirname(os.path.realpath(__file__))+\"/\"\n",
    "data_dir = script_dir+\"../data/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read-in Chiti+2018\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chiti2018(combine_tables=True):\n",
    "    \"\"\"\n",
    "    Loads the data from Chiti et al. (2018) for the MagE and M2FS measurements.\n",
    "    This function reads in the data from the two tables (table5/MagE and table6/M2FS) and\n",
    "    returns them as pandas DataFrames. By default, the two tables are combined into a single\n",
    "    DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the limit columns\n",
    "    def separate_limit_columns(df):\n",
    "        \"\"\"\n",
    "        Separate the limit columns from the value columns in the given DataFrame.\n",
    "        \"\"\"\n",
    "        limit_cols = [col for col in df.columns if col.startswith('l_')]\n",
    "        for l_col in limit_cols:\n",
    "            value_col = l_col.replace('l_', '')  # Corresponding value column\n",
    "\n",
    "            mask_actual = (df[l_col] != '<') & (df[l_col] != '>')\n",
    "            mask_lower = df[l_col] == '>'\n",
    "            mask_upper = df[l_col] == '<'\n",
    "\n",
    "            df[f\"{value_col}_real\"] = np.where(mask_actual, df[value_col], np.nan) # Actual values\n",
    "            df[f\"{value_col}_ll\"] = np.where(mask_lower, df[value_col], np.nan) # Lower limit\n",
    "            df[f\"{value_col}_ul\"] = np.where(mask_upper, df[value_col], np.nan) # Upper limit\n",
    "\n",
    "            # Drop the original limit column & value column\n",
    "            df = df.drop(columns=[value_col])\n",
    "            df = df.drop(columns=[l_col])\n",
    "            df = df.rename(columns={f\"{value_col}_real\": value_col})\n",
    "        return df\n",
    "\n",
    "    if combine_tables:\n",
    "\n",
    "        ## Load the combined table (created by Alex Yelland)\n",
    "        chiti18_df = pd.read_csv('/Users/ayelland/Research/metal-poor-stars/spag/spag/data/abundance_tables/chiti2018/chiti2018_sculptor.csv', comment='#', header=0)\n",
    "        \n",
    "        ## Add columns and extract the limit columns\n",
    "        chiti18_df = separate_limit_columns(chiti18_df)\n",
    "        df_cols_reorder = [\n",
    "            'Reference','Ref','Name','Loc','Type','Sci_key','RA_hms','DEC_dms','RA_deg','DEC_deg',\n",
    "            'logg','Teff','[Ba/H]','Slit',\n",
    "            'A(C)','A(C)_ll','A(C)_ul','e_A(C)',\n",
    "            '[Fe/H]','[Fe/H]_ll','[Fe/H]_ul','e_[Fe/H]',\n",
    "            '[C/Fe]','[C/Fe]_ll','[C/Fe]_ul','e_[C/Fe]','[C/Fe]c',\n",
    "            '[C/Fe]f','[C/Fe]f_ll','[C/Fe]f_ul','e_[C/Fe]f',\n",
    "        ]\n",
    "        chiti18_df = chiti18_df[df_cols_reorder]\n",
    "\n",
    "        ## Fill the NaN values in the RA and DEC columns\n",
    "        for idx, row in chiti18_df.iterrows():\n",
    "            if pd.isna(row['RA_deg']) and pd.notna(row['RA_hms']):  # Ensure RA_hms is not NaN\n",
    "                row['RA_deg'] = coord.ra_hms_to_deg(str(row['RA_hms']), precision=6)\n",
    "                chiti18_df.at[idx, 'RA_deg'] = row['RA_deg']\n",
    "\n",
    "            if pd.isna(row['DEC_deg']) and pd.notna(row['DEC_dms']):  # Ensure DEC_dms is not NaN\n",
    "                row['DEC_deg'] = coord.dec_dms_to_deg(str(row['DEC_dms']), precision=6)\n",
    "                chiti18_df.at[idx, 'DEC_deg'] = row['DEC_deg']\n",
    "\n",
    "            if pd.isna(row['RA_hms']) and pd.notna(row['RA_deg']):  # Ensure RA_deg is not NaN\n",
    "                row['RA_hms'] = coord.ra_deg_to_hms(row['RA_deg'], precision=2)\n",
    "                chiti18_df.at[idx, 'RA_hms'] = row['RA_hms']\n",
    "\n",
    "            if pd.isna(row['DEC_dms']) and pd.notna(row['DEC_deg']):  # Ensure DEC_deg is not NaN\n",
    "                row['DEC_dms'] = coord.dec_deg_to_dms(row['DEC_deg'], precision=2)\n",
    "                chiti18_df.at[idx, 'DEC_dms'] = row['DEC_dms']\n",
    "\n",
    "        return chiti18_df\n",
    "\n",
    "    else:\n",
    "        ## Table 5: MagE Measurements\n",
    "        mage_df = pd.read_csv('/Users/ayelland/Research/metal-poor-stars/spag/spag/data/abundance_tables/chiti2018/table5.csv', comment='#', header=None)\n",
    "        mage_df.columns = [\n",
    "            'ID', 'f5_ID', 'Slit', 'logg', 'Teff', 'l_[Fe/H]KP', '[Fe/H]KP', 'e_[Fe/H]KP', \n",
    "            'l_A(C)', 'A(C)', 'e_A(C)', 'l_[C/Fe]', '[C/Fe]', 'e_[C/Fe]', '[C/Fe]c',\n",
    "            'l_[C/Fe]f','[C/Fe]f', 'e_[C/Fe]f', '[Ba/H]', 'RA_deg', 'DEC_deg'\n",
    "        ]\n",
    "        mage_df['Reference'] = 'Chiti+2018_MagE'\n",
    "        mage_df['Ref'] = 'CHI18'\n",
    "        mage_df = separate_limit_columns(mage_df)\n",
    "        mage_cols_reorder = [\n",
    "            'Reference','Ref','ID','f5_ID','RA_deg','DEC_deg','Slit','logg','Teff',\n",
    "            '[Fe/H]KP','[Fe/H]KP_ll','[Fe/H]KP_ul','e_[Fe/H]KP',\n",
    "            'A(C)','A(C)_ll','A(C)_ul','e_A(C)',\n",
    "            '[C/Fe]','[C/Fe]_ll','[C/Fe]_ul','e_[C/Fe]',\n",
    "            '[C/Fe]c','[C/Fe]f','[C/Fe]f_ll','[C/Fe]f_ul','e_[C/Fe]f','[Ba/H]']\n",
    "        mage_df = mage_df[mage_cols_reorder]\n",
    "\n",
    "        ## Table 6: M2FS Measurements\n",
    "        m2fs_df = pd.read_csv('/Users/ayelland/Research/metal-poor-stars/spag/spag/data/abundance_tables/chiti2018/table6.csv', comment='#', header=None)\n",
    "        m2fs_df.columns = [\n",
    "            'Type', 'ID', 'f6_ID', 'RA_hms', 'DEC_dms', 'logg', 'Teff',\n",
    "            'l_[Fe/H]', '[Fe/H]', 'e_[Fe/H]', \n",
    "            'l_[C/Fe]', '[C/Fe]', 'e_[C/Fe]', '[C/Fe]c', 'l_[C/Fe]f', '[C/Fe]f'\n",
    "        ]\n",
    "        m2fs_df['Reference'] = 'Chiti+2018_M2FS'\n",
    "        m2fs_df['Ref'] = 'CHI18'\n",
    "        m2fs_df = separate_limit_columns(m2fs_df)\n",
    "        m2fs_cols_reorder = [\n",
    "            'Reference','Ref','ID','f6_ID','RA_hms','DEC_dms','Type','logg','Teff',\n",
    "            '[Fe/H]','[Fe/H]_ll','[Fe/H]_ul','e_[Fe/H]',\n",
    "            '[C/Fe]','[C/Fe]_ll','[C/Fe]_ul','e_[C/Fe]',\n",
    "            '[C/Fe]c','[C/Fe]f','[C/Fe]f_ll','[C/Fe]f_ul']\n",
    "        m2fs_df = m2fs_df[m2fs_cols_reorder]\n",
    "\n",
    "        return mage_df, m2fs_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create `load_sculptor()` function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:   127 127 127 127 127 127\n",
      "real:  108 108\n",
      "ulim:  0 0\n",
      "llim:  0 0\n"
     ]
    }
   ],
   "source": [
    "def load_chiti2018_extract_carbon_data_original(chiti2018_df):\n",
    "    \"\"\"\n",
    "    Extracts the [Fe/H], [C/Fe], [C/Fe]_ul, and [C/Fe]_ll values from the\n",
    "    Chiti et al. (2018) DataFrame. The function accounts for the different\n",
    "    column names used in the MagE and M2FS tables.\n",
    "\n",
    "    chi18_df: pandas DataFrame\n",
    "        MagE or M2FS DataFrame containing the data from Chiti et al. (2018).\n",
    "\n",
    "    Returns:\n",
    "        feh: list\n",
    "            Extracted [Fe/H] values.\n",
    "        feh_ul: list\n",
    "            Extracted [Fe/H] upper limit values.\n",
    "        feh_ll: list\n",
    "            Extracted [Fe/H] lower limit values.\n",
    "        cfe: list\n",
    "            Extracted [C/Fe] values.\n",
    "        cfe_ul: list\n",
    "            Extracted [C/Fe] upper limit values.\n",
    "        cfe_ll: list\n",
    "            Extracted [C/Fe] lower limit values.\n",
    "    \"\"\"\n",
    "    feh = []\n",
    "    feh_ul = []\n",
    "    feh_ll = []\n",
    "    cfe = []\n",
    "    cfe_ul = []\n",
    "    cfe_ll = []\n",
    "    \n",
    "    feh_str = '[Fe/H]KP' if '[Fe/H]KP' in chiti2018_df.columns else '[Fe/H]'\n",
    "\n",
    "    for idx, row in chiti2018_df.iterrows():\n",
    "        if pd.isna(row[feh_str]):\n",
    "            if pd.isna(row[feh_str+'_ul']):\n",
    "                if pd.isna(row[feh_str+'_ll']):\n",
    "                    feh.append(np.nan)\n",
    "                    feh_ul.append(np.nan)\n",
    "                    feh_ll.append(np.nan)\n",
    "                    cfe.append(np.nan)\n",
    "                    cfe_ul.append(np.nan)\n",
    "                    cfe_ll.append(np.nan)\n",
    "                else:\n",
    "                    feh.append(np.nan)\n",
    "                    feh_ul.append(np.nan)\n",
    "                    feh_ll.append(row[feh_str+'_ll'])\n",
    "\n",
    "                    if pd.isna(row['[C/Fe]']):\n",
    "                        if pd.isna(row['[C/Fe]_ul']):\n",
    "                            if pd.isna(row['[C/Fe]_ll']):\n",
    "                                feh[-1] = np.nan\n",
    "                                feh_ul[-1] = np.nan\n",
    "                                feh_ll[-1] = np.nan\n",
    "                                cfe.append(np.nan)\n",
    "                                cfe_ul.append(np.nan)\n",
    "                                cfe_ll.append(np.nan)\n",
    "                            else:\n",
    "                                cfe.append(np.nan)\n",
    "                                cfe_ul.append(np.nan)\n",
    "                                cfe_ll.append(row['[C/Fe]_ll'])\n",
    "                        else:   \n",
    "                            cfe.append(np.nan)\n",
    "                            cfe_ul.append(np.nan)\n",
    "                            cfe_ll.append(row['[C/Fe]_ul'])\n",
    "                    else:\n",
    "                        cfe.append(np.nan)\n",
    "                        cfe_ul.append(np.nan)\n",
    "                        cfe_ll.append(row['[C/Fe]'])\n",
    "            else:\n",
    "                feh.append(np.nan)\n",
    "                feh_ul.append(row[feh_str+'_ul'])\n",
    "                feh_ll.append(np.nan)\n",
    "                if pd.isna(row['[C/Fe]']):\n",
    "                    if pd.isna(row['[C/Fe]_ul']):\n",
    "                        if pd.isna(row['[C/Fe]_ll']):\n",
    "                            feh[-1] = np.nan\n",
    "                            feh_ul[-1] = np.nan\n",
    "                            feh_ll[-1] = np.nan\n",
    "                            cfe.append(np.nan)\n",
    "                            cfe_ul.append(np.nan)\n",
    "                            cfe_ll.append(np.nan)\n",
    "                        else:\n",
    "                            cfe.append(np.nan)\n",
    "                            cfe_ul.append(row['[C/Fe]_ll'])\n",
    "                            cfe_ll.append(np.nan)\n",
    "                    else:   \n",
    "                        cfe.append(np.nan)\n",
    "                        cfe_ul.append(row['[C/Fe]_ul'])\n",
    "                        cfe_ll.append(np.nan)\n",
    "                else:\n",
    "                    cfe.append(np.nan)\n",
    "                    cfe_ul.append(row['[C/Fe]'])\n",
    "                    cfe_ll.append(np.nan)\n",
    "        else:\n",
    "            feh.append(row[feh_str])\n",
    "            feh_ul.append(np.nan)\n",
    "            feh_ll.append(np.nan)\n",
    "            if pd.isna(row['[C/Fe]']):\n",
    "                if pd.isna(row['[C/Fe]_ul']):\n",
    "                    if pd.isna(row['[C/Fe]_ll']):\n",
    "                        feh[-1] = np.nan\n",
    "                        feh_ul[-1] = np.nan\n",
    "                        feh_ll[-1] = np.nan\n",
    "                        cfe.append(np.nan)\n",
    "                        cfe_ul.append(np.nan)\n",
    "                        cfe_ll.append(np.nan)\n",
    "                    else:\n",
    "                        cfe.append(row['[C/Fe]_ll'])\n",
    "                        cfe_ul.append(np.nan)\n",
    "                        cfe_ll.append(np.nan)\n",
    "                else:   \n",
    "                    cfe.append(row['[C/Fe]_ul'])\n",
    "                    cfe_ul.append(np.nan)\n",
    "                    cfe_ll.append(np.nan)\n",
    "            else:\n",
    "                cfe.append(row['[C/Fe]'])\n",
    "                cfe_ul.append(np.nan)\n",
    "                cfe_ll.append(np.nan)\n",
    "\n",
    "    print(\"len:  \", len(feh), len(feh_ul), len(feh_ll), len(cfe), len(cfe_ul), len(cfe_ll))\n",
    "    print(\"real: \", np.sum(~np.isnan(feh)), np.sum(~np.isnan(cfe)))\n",
    "    print(\"ulim: \", np.sum(~np.isnan(feh_ul)), np.sum(~np.isnan(cfe_ul)))\n",
    "    print(\"llim: \", np.sum(~np.isnan(feh_ll)), np.sum(~np.isnan(cfe_ll)))\n",
    "\n",
    "    return feh, feh_ul, feh_ll, cfe, cfe_ul, cfe_ll\n",
    "\n",
    "chiti18_df = load_chiti2018(combine_tables=True)\n",
    "feh, feh_ul, feh_ll, cfe, cfe_ul, cfe_ll = load_chiti2018_extract_carbon_data_original(chiti18_df)\n",
    "\n",
    "chiti18_df_updated = chiti18_df.copy()\n",
    "chiti18_df_updated['FeH'] = feh\n",
    "chiti18_df_updated['FeH_ll'] = feh_ll\n",
    "chiti18_df_updated['FeH_ul'] = feh_ul\n",
    "chiti18_df_updated['C/Fe'] = cfe\n",
    "chiti18_df_updated['C/Fe_ll'] = cfe_ll\n",
    "chiti18_df_updated['C/Fe_ul'] = cfe_ul\n",
    "\n",
    "chiti18_df_updated.to_csv('/Users/ayelland/Research/metal-poor-stars/project/carbon-project/updated_df.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Dropped the CaII, TiII, VII, CrII, MnII, FeII columns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geisler+2005: 4\n",
      "Hill+2019: 87\n",
      "JAB15: 5\n",
      "KIR12: 1\n",
      "SHE03: 5\n",
      "SIM15: 5\n",
      "Skuladottir+2015: 1\n",
      "Skuladottir+2019: 1\n",
      "TAF10: 2\n",
      "Chiti+2018_M2FS: 100\n",
      "Chiti+2018_MagE: 27\n"
     ]
    }
   ],
   "source": [
    "def load_sculptor():\n",
    "\n",
    "    sculptor_refs = [\n",
    "        'CHI18','GEI05','HIL19','JAB15','KIR12',#'REI20',\n",
    "        'SIM15','SKU15','SKU17','SKU19','SKU24','SHE03',\n",
    "        'TAF10'\n",
    "        # 'REI20' could be included, but it lacks carbon abundances and does not have DW identifiers in jinabase\n",
    "    ]\n",
    "\n",
    "    ## JINAbase\n",
    "    # -------------------------------------------------- #\n",
    "    jinabase = rd.load_jinabase(priority=1)\n",
    "\n",
    "    ## Filter JINAbase for Sculptor (by Star Name)\n",
    "    jinabase_nan = jinabase[jinabase['Name'].isna()]  # Rows where 'Name' is NaN\n",
    "    jinabase_non_nan = jinabase[jinabase['Name'].notna()]  # Rows where 'Name' is not NaN\n",
    "    jinabase_sculptor1 = jinabase_non_nan[jinabase_non_nan['Name'].str.lower().str.contains('scl')]\n",
    "\n",
    "    ## Filter JINAbase for Sculptor (by Reference)\n",
    "    sculptor_refs = [ref for ref in sculptor_refs if ref not in jinabase_sculptor1['Ref'].unique()]\n",
    "    jinabase_sculptor2 = jinabase[jinabase['Ref'].isin(sculptor_refs)]\n",
    "\n",
    "    ## References Remaining\n",
    "    sculptor_refs = [ref for ref in sculptor_refs if ref not in jinabase_sculptor2['Ref'].unique()]\n",
    "\n",
    "    ## Concatenate the DataFrames\n",
    "    jinabase_sculptor = pd.concat([jinabase_sculptor1, jinabase_sculptor2], ignore_index=True)\n",
    "\n",
    "\n",
    "    ## Manually add specific references\n",
    "    # -------------------------------------------------- #\n",
    "\n",
    "    ## Chiti+2018\n",
    "    chiti18_df = load_chiti2018(combine_tables=True)\n",
    "\n",
    "    chiti18_df['epsc'] = chiti18_df['A(C)']\n",
    "    chiti18_df['ulc'] = chiti18_df['A(C)_ul']\n",
    "    chiti18_df['llc'] = chiti18_df['A(C)_ll']\n",
    "    chiti18_df['e_epsc'] = chiti18_df['A(C)_ul']\n",
    "\n",
    "    chiti18_df.drop(columns=[\n",
    "        'logg',\n",
    "        '[Ba/H]',\n",
    "        'Slit',\n",
    "        'A(C)',\n",
    "        'A(C)_ll',\n",
    "        'A(C)_ul',\n",
    "        'e_A(C)',\n",
    "        # '[Fe/H]_ll',\n",
    "        # '[Fe/H]_ul',\n",
    "        # 'e_[Fe/H]',\n",
    "        # '[C/Fe]_ll',\n",
    "        # '[C/Fe]_ul',\n",
    "        # 'e_[C/Fe]',\n",
    "        # '[C/Fe]c',\n",
    "        # '[C/Fe]f',\n",
    "        # '[C/Fe]f_ll',\n",
    "        # '[C/Fe]f_ul',\n",
    "        # 'e_[C/Fe]f'\n",
    "    ], inplace=True)\n",
    "\n",
    "    # chiti18_df.to_csv('/Users/ayelland/Research/metal-poor-stars/project/carbon-project/chiti2018_sculptor.csv', index=False)\n",
    "\n",
    "    ## Skuladottir+2017\n",
    "    ## Skuladottir+2024\n",
    "    ## Frebel+2010\n",
    "    ## Jacobson\n",
    "\n",
    "    ## Combine the DataFrames\n",
    "    # -------------------------------------------------- #\n",
    "    sculptor_df = pd.concat([jinabase_sculptor, chiti18_df], ignore_index=True, sort=False)\n",
    "    sculptor_df.to_csv('/Users/ayelland/Research/metal-poor-stars/project/carbon-project/sculptor_df.csv', index=False)\n",
    "\n",
    "    return sculptor_df\n",
    "\n",
    "\n",
    "\n",
    "sculptor_df = load_sculptor()\n",
    "display(sculptor_df.shape[0])\n",
    "\n",
    "\n",
    "sculptor_df_carbon = sculptor_df[sculptor_df['[C/Fe]'].notna() | sculptor_df['ulc'].notna()]\n",
    "\n",
    "# sculptor_df_carbon = sculptor_df[sculptor_df['[C/Fe]'] | sculptor_df['ulc']]\n",
    "display(sculptor_df_carbon.shape[0])\n",
    "\n",
    "for ref in list(sculptor_df['Reference'].unique()):\n",
    "    print(f\"{ref}: {sculptor_df[sculptor_df['Reference'] == ref].shape[0]}\")\n",
    "# display(sculptor_df_carbon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
