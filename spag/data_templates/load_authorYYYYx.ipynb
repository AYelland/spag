{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f6d567",
   "metadata": {},
   "source": [
    "---\n",
    "## Helpful Comments & Instructions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f44282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is a example/template for the `read_data.py` script, that loads the\n",
    "# data from a specific paper and reformats it into the standard format used by\n",
    "# SPAG. To use this, copy the following function into a testing script or\n",
    "# Jupyter notebook, and modify the function name and contents as needed.\n",
    "\n",
    "\n",
    "# Specifically, change all instances of...\n",
    "\n",
    "# - `authorYYYYx` to the first author's last name (maybe with their first \n",
    "# initial of there is a duplicate last name) and year of the paper. When there\n",
    "# are instances of an author releasing more than one paper in a year, append a\n",
    "# letter to the year in `x` position.\n",
    "#   (e.g., `Ji et al. 2016a` --> `ji2016a`, if there is also a \n",
    "#       `Ji et al. 2016b`)\n",
    "#   (e.g., `Hansen et al. 2018` --> `hansent2018c`, if there are multiple\n",
    "#       authors with the same last name and this was T. Hansen's 3rd paper in \n",
    "#       2018)\n",
    "\n",
    "# - the path to the data files to point to the correct location of the data \n",
    "#   tables.\n",
    "#   (e.g., `data_dir + \"abundance_tables/authorYYYYx/table1.csv\"`)\n",
    "\n",
    "# - The `Reference` and `Ref` columns to match the citation for the paper.\n",
    "#   --> `Reference` column should be in the form 'Author+Year'.\n",
    "#       (e.g., 'Ji+2016a', 'HansenT+2018c')\n",
    "#   --> `Ref` column should shortened form of the reference, typically the \n",
    "#       first 3 letters of the author's last name (all uppercase) and the last\n",
    "#       two digits of the year, with a letter appended if there are multiple\n",
    "#       papers by the same author(s) in that year. (e.g.'JI16a', 'HANt18c')\n",
    "\n",
    "# - The `Loc` column to match the type of object the stars are in. Use:\n",
    "#   --> 'HA' for halo stars\n",
    "#   --> 'BU' for bulge stars\n",
    "#   --> 'DS' for disk stars\n",
    "#   --> 'DW' for dwarf galaxy stars\n",
    "#   --> 'UF' for ultra-faint dwarf galaxy stars\n",
    "#   --> 'GC' for globular cluster stars\n",
    "\n",
    "# - The `System` column to match the name of the system the stars are in, if \n",
    "#   applicable and not already in the data table.\n",
    "\n",
    "\n",
    "# Beyond this, confirm that the datafiles are reading in correctly, and that\n",
    "# the columns are being filled in properly. You may need to modify how the data \n",
    "# is read in or the structure of the datafile themselves, depending on the \n",
    "# format of the data tables.\n",
    "\n",
    "# Things to be wary of...\n",
    "\n",
    "# - Some papers use different formats for the species names, such as \"Fe I\" vs\n",
    "#   \"FeI\" vs \"Fe1\". The `ion_to_species()` function should be able to handle \n",
    "#   most of these, but you may need to modify the datafile if there are any \n",
    "#   issues, or contact A. Yelland.\n",
    "\n",
    "# - Some papers may not provide all the necessary columns, such as separate\n",
    "#   upper/lower limit flag column. You may need to modify the datafile to add\n",
    "#   the flag columns.\n",
    "\n",
    "# - Additionally, different authors at different times may use different solar\n",
    "#   abundance scales. The `get_solar()` function can be used to retrieve the\n",
    "#   solar abundances of the most commonly used scales, but if one is not\n",
    "#   available, please let A. Yelland know.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12153eca",
   "metadata": {},
   "source": [
    "---\n",
    "## Package Imports & Directories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65303612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import (division, print_function, absolute_import,\n",
    "                        unicode_literals)\n",
    "import  sys, os, glob, time, IPython\n",
    "\n",
    "import astropy.constants as const\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "# from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "\n",
    "# from PyAstronomy import pyasl\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "colors = sns.color_palette(\"colorblind\", 20)\n",
    "\n",
    "# from smh import Session\n",
    "\n",
    "from spag.read_data import *\n",
    "from spag.convert import *\n",
    "from spag.utils import *\n",
    "# from spag.calculate import *\n",
    "# import spag.read_data as rd\n",
    "import spag.coordinates as coord\n",
    "\n",
    "# import alexmods.read_data as rd\n",
    "\n",
    "script_dir = \"/\".join(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]) + \"/\"\n",
    "# script_dir = os.path.dirname(os.path.realpath(__file__))+\"/\"\n",
    "data_dir = '/Users/ayelland/Research/metal-poor-stars/spag/spag/data/'\n",
    "plotting_dir = script_dir+\"plots/\"\n",
    "if not os.path.exists(plotting_dir):\n",
    "    os.makedirs(plotting_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb48c53",
   "metadata": {},
   "source": [
    "---\n",
    "## Template Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b595691",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ayelland/Research/metal-poor-stars/spag/spag/data/abundance_tables/authorYYYYx/table1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 112\u001b[0m\n\u001b[1;32m    108\u001b[0m     authorYYYYx_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Fe/Fe]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul[Fe/Fe]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[FeII/Fe]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul[FeII/Fe]\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m authorYYYYx_df\n\u001b[0;32m--> 112\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_authorYYYYx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m display(df)\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mload_authorYYYYx\u001b[0;34m(io)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mLoad the Author et al. YYYYx data for the <grouping or classification of stars>.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mTable 3 - Abundance Table\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m## Read in the data tables\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m obs_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabundance_tables/authorYYYYx/table1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m#\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNaN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN/A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn/a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m param_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabundance_tables/authorYYYYx/table3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m, na_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn/a\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m abund_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabundance_tables/authorYYYYx/table4.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m, na_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn/a\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.anaconda3/envs/spag/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.anaconda3/envs/spag/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.anaconda3/envs/spag/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.anaconda3/envs/spag/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.anaconda3/envs/spag/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ayelland/Research/metal-poor-stars/spag/spag/data/abundance_tables/authorYYYYx/table1.csv'"
     ]
    }
   ],
   "source": [
    "def load_authorYYYYx(io=None):\n",
    "    \"\"\"\n",
    "    Load the Author et al. YYYYx data for the <grouping or classification of stars>.\n",
    "\n",
    "    Table 1 - Observations\n",
    "    Table 2 - Stellar Parameters\n",
    "    Table 3 - Abundance Table\n",
    "    \"\"\"\n",
    "\n",
    "    ## Read in the data tables\n",
    "    obs_df = pd.read_csv(data_dir + \"abundance_tables/authorYYYYx/table1.csv\", comment=\"#\", na_values=[\"\", \" \", \"nan\", \"NaN\", \"N/A\", \"n/a\"])\n",
    "    param_df = pd.read_csv(data_dir + \"abundance_tables/authorYYYYx/table3.csv\", comment=\"#\", na_values=[\"\", \" \", \"nan\", \"NaN\", \"N/A\", \"n/a\"])\n",
    "    abund_df = pd.read_csv(data_dir + \"abundance_tables/authorYYYYx/table4.csv\", comment=\"#\", na_values=[\"\", \" \", \"nan\", \"NaN\", \"N/A\", \"n/a\"])\n",
    "\n",
    "    ## Make the new column names\n",
    "    species = []\n",
    "    for ion in abund_df[\"Species\"].unique():\n",
    "        species_i = ion_to_species(ion)\n",
    "        elem_i = ion_to_element(ion)\n",
    "        if species_i not in species:\n",
    "            species.append(species_i)\n",
    "\n",
    "    epscols = [make_epscol(s) for s in species]\n",
    "    ulcols = [make_ulcol(s) for s in species]\n",
    "    XHcols = [make_XHcol(s).replace(\" \", \"\") for s in species]\n",
    "    ulXHcols = ['ul' + col for col in XHcols]\n",
    "    XFecols = [make_XFecol(s).replace(\" \", \"\") for s in species]\n",
    "    ulXFecols = ['ul' + col for col in XFecols]\n",
    "    errcols = [make_errcol(s) for s in species]\n",
    "\n",
    "    ## New dataframe with proper columns\n",
    "    authorYYYYx_df = pd.DataFrame(\n",
    "                    columns=['I/O','Name','Simbad_Identifier','Reference','Ref','Loc','System','RA_hms','RA_deg','DEC_dms','DEC_deg',\n",
    "                    'Teff','logg','Fe/H','Vmic'] + epscols + ulcols + XHcols + ulXHcols + XFecols \n",
    "                    + ulXFecols + errcols)\n",
    "    for i, name in enumerate(abund_df['Name'].unique()):\n",
    "        authorYYYYx_df.loc[i,'Name'] = name\n",
    "        authorYYYYx_df.loc[i,'Simbad_Identifier'] = obs_df.loc[obs_df['Name'] == name, 'Simbad_Identifier'].values[0]\n",
    "        authorYYYYx_df.loc[i,'Reference'] = 'Author+YYYYx'\n",
    "        authorYYYYx_df.loc[i,'Ref'] = 'AUTYYx'\n",
    "        authorYYYYx_df.loc[i,'I/O'] = 1\n",
    "        authorYYYYx_df.loc[i,'Loc'] = 'UF' # [HA, BU, DS, DW, UF, GC]\n",
    "        authorYYYYx_df.loc[i,'System'] = obs_df.loc[obs_df['Name'] == name, 'System'].values[0]\n",
    "        authorYYYYx_df.loc[i,'RA_hms'] = obs_df.loc[obs_df['Name'] == name, 'RA_hms'].values[0]\n",
    "        authorYYYYx_df.loc[i,'RA_deg'] = coord.ra_hms_to_deg(authorYYYYx_df.loc[i,'RA_hms'], precision=6)\n",
    "        authorYYYYx_df.loc[i,'DEC_dms'] = obs_df.loc[obs_df['Name'] == name, 'DEC_dms'].values[0]\n",
    "        authorYYYYx_df.loc[i,'DEC_deg'] = coord.dec_dms_to_deg(authorYYYYx_df.loc[i,'DEC_dms'], precision=2)\n",
    "        authorYYYYx_df.loc[i,'Teff'] = param_df.loc[param_df['Name'] == name, 'Teff'].values[0]\n",
    "        authorYYYYx_df.loc[i,'logg'] = param_df.loc[param_df['Name'] == name, 'logg'].values[0]\n",
    "        authorYYYYx_df.loc[i,'Fe/H'] = param_df.loc[param_df['Name'] == name, 'Fe/H'].values[0]\n",
    "        authorYYYYx_df.loc[i,'Vmic'] = param_df.loc[param_df['Name'] == name, 'Vmic'].values[0]\n",
    "\n",
    "        ## Fill in data\n",
    "        star_df = abund_df[abund_df['Name'] == name]\n",
    "        for j, row in star_df.iterrows():\n",
    "            ion = row[\"Species\"]\n",
    "            species_i = ion_to_species(ion)\n",
    "            elem_i = ion_to_element(ion)\n",
    "\n",
    "            logepsX_sun_a09 = get_solar(elem_i, version='asplund2009')[0]\n",
    "            logepsFe_a09 = star_df.loc[star_df['Species'] == 'Fe I', 'logepsX'].values[0]\n",
    "            feh_a09 = logepsFe_a09 - get_solar('Fe', version='asplund2009')[0]\n",
    "\n",
    "            ## Assign epsX values\n",
    "            col = make_epscol(species_i)\n",
    "            if col in epscols:\n",
    "                authorYYYYx_df.loc[i, col] = row[\"logepsX\"] if pd.isna(row[\"l_logepsX\"]) else np.nan\n",
    "\n",
    "            ## Assign ulX values\n",
    "            col = make_ulcol(species_i)\n",
    "            if col in ulcols:\n",
    "                authorYYYYx_df.loc[i, col] = row[\"logepsX\"] if pd.notna(row[\"l_logepsX\"]) else np.nan\n",
    "\n",
    "            ## Assign [X/H] and ul[X/H]values\n",
    "            col = make_XHcol(species_i).replace(\" \", \"\")\n",
    "            if col in XHcols:\n",
    "                if pd.isna(row[\"l_[X/H]\"]):\n",
    "                    authorYYYYx_df.loc[i, col] = normal_round(row[\"logepsX\"] - logepsX_sun_a09, 2)\n",
    "                    authorYYYYx_df.loc[i, 'ul'+col] = np.nan\n",
    "                else:\n",
    "                    authorYYYYx_df.loc[i, col] = np.nan\n",
    "                    authorYYYYx_df.loc[i, 'ul'+col] = normal_round(row[\"logepsX\"] - logepsX_sun_a09, 2)\n",
    "                if 'e_[X/H]' in row.index:\n",
    "                    authorYYYYx_df.loc[i, 'e_'+col] = row[\"e_[X/H]\"]\n",
    "\n",
    "            ## Assign [X/Fe] values\n",
    "            col = make_XFecol(species_i).replace(\" \", \"\")\n",
    "            if col in XFecols:\n",
    "                if pd.isna(row[\"l_[X/Fe]\"]):\n",
    "                    authorYYYYx_df.loc[i, col] = normal_round((row[\"logepsX\"] - logepsX_sun_a09) - feh_a09, 2)\n",
    "                    authorYYYYx_df.loc[i, 'ul'+col] = np.nan\n",
    "                else:\n",
    "                    authorYYYYx_df.loc[i, col] = np.nan\n",
    "                    authorYYYYx_df.loc[i, 'ul'+col] = normal_round((row[\"logepsX\"] - logepsX_sun_a09) - feh_a09, 2)\n",
    "                if 'e_[X/Fe]' in row.index:\n",
    "                    authorYYYYx_df.loc[i, 'e_'+col] = row[\"e_[X/Fe]\"]\n",
    "\n",
    "            ## Assign error values\n",
    "            col = make_errcol(species_i)\n",
    "            if col in errcols:\n",
    "                e_logepsX = row.get(\"e_logepsX\", np.nan)\n",
    "                if pd.notna(e_logepsX):\n",
    "                    authorYYYYx_df.loc[i, col] = e_logepsX\n",
    "                else:\n",
    "                    authorYYYYx_df.loc[i, col] = np.nan\n",
    "\n",
    "    ## Drop the Fe/Fe columns\n",
    "    authorYYYYx_df.drop(columns=['[Fe/Fe]','ul[Fe/Fe]','[FeII/Fe]','ul[FeII/Fe]'], inplace=True, errors='ignore')\n",
    "\n",
    "    return authorYYYYx_df\n",
    "\n",
    "df = load_authorYYYYx()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceecde7",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing Zone\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93d02d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/O</th>\n",
       "      <th>Name</th>\n",
       "      <th>Simbad_Identifier</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Loc</th>\n",
       "      <th>System</th>\n",
       "      <th>RA_hms</th>\n",
       "      <th>RA_deg</th>\n",
       "      <th>DEC_dms</th>\n",
       "      <th>...</th>\n",
       "      <th>e_[Sc/H]</th>\n",
       "      <th>e_[Ti1/H]</th>\n",
       "      <th>e_[Ti/H]</th>\n",
       "      <th>e_[Cr/H]</th>\n",
       "      <th>e_[Mn/H]</th>\n",
       "      <th>e_[Fe/H]</th>\n",
       "      <th>e_[Fe2/H]</th>\n",
       "      <th>e_[Co/H]</th>\n",
       "      <th>e_[Ni/H]</th>\n",
       "      <th>e_[Zn/H]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HD 2796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:31:16.91</td>\n",
       "      <td>7.820458</td>\n",
       "      <td>-16:47:40.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HD 122563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14:02:31.85</td>\n",
       "      <td>210.632708</td>\n",
       "      <td>+9:41:09.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>HD 186478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19:45:14.14</td>\n",
       "      <td>296.308917</td>\n",
       "      <td>-17:29:27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>BD+17 3248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:28:14.47</td>\n",
       "      <td>262.060292</td>\n",
       "      <td>+17:30:35.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>BD-18 5550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19:58:49.74</td>\n",
       "      <td>299.70725</td>\n",
       "      <td>-18:12:11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>CD-38 245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:46:36.19</td>\n",
       "      <td>11.650792</td>\n",
       "      <td>-37:39:33.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>BS 16467-062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13:42:00.63</td>\n",
       "      <td>205.502625</td>\n",
       "      <td>+17:48:40.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>BS 16477-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14:32:56.91</td>\n",
       "      <td>218.237125</td>\n",
       "      <td>+6:46:06.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>BS 17569-049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22:04:58.36</td>\n",
       "      <td>331.243167</td>\n",
       "      <td>+4:01:32.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22169-035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4:12:13.88</td>\n",
       "      <td>63.057833</td>\n",
       "      <td>+12:05:05.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22172-002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3:14:20.84</td>\n",
       "      <td>48.586833</td>\n",
       "      <td>+10:35:11.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22186-025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4:24:32.8</td>\n",
       "      <td>66.136667</td>\n",
       "      <td>+37:09:02.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22189-009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:41:42.37</td>\n",
       "      <td>40.426542</td>\n",
       "      <td>+13:28:10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22873-055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19:53:49.78</td>\n",
       "      <td>298.457417</td>\n",
       "      <td>+59:40:00.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22873-166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20:19:22.02</td>\n",
       "      <td>304.84175</td>\n",
       "      <td>+61:30:14.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22878-101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:45:31.44</td>\n",
       "      <td>251.381</td>\n",
       "      <td>+8:14:45.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22885-096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20:20:51.17</td>\n",
       "      <td>305.213208</td>\n",
       "      <td>+39:53:30.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22891-209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19:42:02.16</td>\n",
       "      <td>295.509</td>\n",
       "      <td>+61:03:44.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22892-052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22:17:01.65</td>\n",
       "      <td>334.256875</td>\n",
       "      <td>+16:39:27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22896-154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19:42:26.88</td>\n",
       "      <td>295.612</td>\n",
       "      <td>+56:58:34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22897-008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21:03:11.85</td>\n",
       "      <td>315.799375</td>\n",
       "      <td>+65:05:08.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22948-066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21:44:51.17</td>\n",
       "      <td>326.213208</td>\n",
       "      <td>+37:27:54.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22949-037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:26:29.8</td>\n",
       "      <td>351.624167</td>\n",
       "      <td>+2:39:57.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22952-015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:37:28.69</td>\n",
       "      <td>354.369542</td>\n",
       "      <td>+5:47:56.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22953-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:02:15.85</td>\n",
       "      <td>15.566042</td>\n",
       "      <td>+61:43:45.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22956-050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21:58:05.83</td>\n",
       "      <td>329.524292</td>\n",
       "      <td>+65:13:27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22966-057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:48:57.76</td>\n",
       "      <td>357.240667</td>\n",
       "      <td>+29:39:22.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 22968-014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3:06:29.5</td>\n",
       "      <td>46.622917</td>\n",
       "      <td>+54:30:32.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 29491-053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22:36:56.3</td>\n",
       "      <td>339.234583</td>\n",
       "      <td>+28:31:06.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 29502-042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22:21:48.82</td>\n",
       "      <td>335.453417</td>\n",
       "      <td>+2:28:44.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 29516-024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22:26:15.35</td>\n",
       "      <td>336.563958</td>\n",
       "      <td>+2:51:46.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 29518-051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:24:10.01</td>\n",
       "      <td>21.041708</td>\n",
       "      <td>+28:15:21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 30325-094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14:54:39.27</td>\n",
       "      <td>223.663625</td>\n",
       "      <td>+4:21:38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>CS 31082-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Author+YYYYx</td>\n",
       "      <td>AUTYYx</td>\n",
       "      <td>UF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:29:31.13</td>\n",
       "      <td>22.379708</td>\n",
       "      <td>+16:00:45.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows  165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   I/O          Name Simbad_Identifier     Reference     Ref Loc System  \\\n",
       "0    1       HD 2796               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "1    1     HD 122563               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "2    1     HD 186478               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "3    1    BD+17 3248               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "4    1    BD-18 5550               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "5    1     CD-38 245               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "6    1  BS 16467-062               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "7    1  BS 16477-003               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "8    1  BS 17569-049               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "9    1  CS 22169-035               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "10   1  CS 22172-002               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "11   1  CS 22186-025               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "12   1  CS 22189-009               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "13   1  CS 22873-055               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "14   1  CS 22873-166               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "15   1  CS 22878-101               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "16   1  CS 22885-096               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "17   1  CS 22891-209               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "18   1  CS 22892-052               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "19   1  CS 22896-154               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "20   1  CS 22897-008               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "21   1  CS 22948-066               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "22   1  CS 22949-037               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "23   1  CS 22952-015               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "24   1  CS 22953-003               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "25   1  CS 22956-050               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "26   1  CS 22966-057               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "27   1  CS 22968-014               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "28   1  CS 29491-053               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "29   1  CS 29502-042               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "30   1  CS 29516-024               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "31   1  CS 29518-051               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "32   1  CS 30325-094               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "33   1  CS 31082-001               NaN  Author+YYYYx  AUTYYx  UF    NaN   \n",
       "\n",
       "         RA_hms      RA_deg      DEC_dms  ... e_[Sc/H] e_[Ti1/H] e_[Ti/H]  \\\n",
       "0    0:31:16.91    7.820458  -16:47:40.8  ...     0.11      0.06     0.09   \n",
       "1   14:02:31.85  210.632708   +9:41:09.9  ...     0.10      0.10     0.10   \n",
       "2   19:45:14.14  296.308917  -17:29:27.1  ...     0.12      0.07     0.10   \n",
       "3   17:28:14.47  262.060292  +17:30:35.8  ...     0.16      0.08     0.17   \n",
       "4   19:58:49.74   299.70725  -18:12:11.1  ...     0.09      0.04     0.09   \n",
       "5    0:46:36.19   11.650792  -37:39:33.6  ...      NaN      0.04     0.11   \n",
       "6   13:42:00.63  205.502625  +17:48:40.8  ...     0.06      0.17     0.18   \n",
       "7   14:32:56.91  218.237125   +6:46:06.9  ...     0.14      0.10     0.12   \n",
       "8   22:04:58.36  331.243167   +4:01:32.1  ...     0.16      0.06     0.12   \n",
       "9    4:12:13.88   63.057833  +12:05:05.0  ...     0.11      0.02     0.14   \n",
       "10   3:14:20.84   48.586833  +10:35:11.2  ...     0.06      0.09     0.12   \n",
       "11    4:24:32.8   66.136667  +37:09:02.5  ...     0.06      0.09     0.06   \n",
       "12   2:41:42.37   40.426542  +13:28:10.5  ...     0.08      0.16     0.11   \n",
       "13  19:53:49.78  298.457417  +59:40:00.1  ...     0.05      0.05     0.11   \n",
       "14  20:19:22.02   304.84175  +61:30:14.9  ...     0.10      0.09     0.13   \n",
       "15  16:45:31.44     251.381   +8:14:45.4  ...     0.03      0.14     0.09   \n",
       "16  20:20:51.17  305.213208  +39:53:30.1  ...     0.08      0.07     0.11   \n",
       "17  19:42:02.16     295.509  +61:03:44.6  ...     0.05      0.04     0.12   \n",
       "18  22:17:01.65  334.256875  +16:39:27.1  ...     0.10      0.12     0.13   \n",
       "19  19:42:26.88     295.612  +56:58:34.0  ...     0.08      0.06     0.12   \n",
       "20  21:03:11.85  315.799375  +65:05:08.8  ...     0.05      0.05     0.11   \n",
       "21  21:44:51.17  326.213208  +37:27:54.9  ...     0.03      0.11     0.08   \n",
       "22   23:26:29.8  351.624167   +2:39:57.9  ...     0.14      0.09     0.15   \n",
       "23  23:37:28.69  354.369542   +5:47:56.6  ...     0.05      0.09     0.11   \n",
       "24   1:02:15.85   15.566042  +61:43:45.8  ...     0.08      0.09     0.10   \n",
       "25  21:58:05.83  329.524292  +65:13:27.1  ...     0.07      0.04     0.12   \n",
       "26  23:48:57.76  357.240667  +29:39:22.8  ...     0.08      0.04     0.08   \n",
       "27    3:06:29.5   46.622917  +54:30:32.5  ...     0.07      0.12     0.12   \n",
       "28   22:36:56.3  339.234583  +28:31:06.4  ...     0.08      0.08     0.10   \n",
       "29  22:21:48.82  335.453417   +2:28:44.8  ...     0.13      0.06     0.09   \n",
       "30  22:26:15.35  336.563958   +2:51:46.2  ...     0.10      0.03     0.09   \n",
       "31   1:24:10.01   21.041708  +28:15:21.0  ...     0.08      0.04     0.09   \n",
       "32  14:54:39.27  223.663625   +4:21:38.0  ...     0.09      0.05     0.10   \n",
       "33   1:29:31.13   22.379708  +16:00:45.4  ...     0.07      0.09     0.14   \n",
       "\n",
       "   e_[Cr/H] e_[Mn/H] e_[Fe/H] e_[Fe2/H] e_[Co/H] e_[Ni/H] e_[Zn/H]  \n",
       "0      0.13     0.01     0.13      0.13      NaN     0.14      NaN  \n",
       "1      0.17     0.06     0.17      0.13     0.13     0.09      NaN  \n",
       "2      0.14     0.04     0.18      0.14     0.19     0.15      NaN  \n",
       "3      0.20     0.02     0.15      0.09      NaN     0.08      NaN  \n",
       "4      0.10     0.05     0.12      0.10     0.12     0.10      NaN  \n",
       "5      0.12     0.03     0.20      0.13     0.08      NaN      NaN  \n",
       "6      0.29     0.03     0.14      0.12     0.10     0.03      NaN  \n",
       "7      0.12     0.11     0.12      0.05     0.09     0.07      NaN  \n",
       "8      0.08     0.05     0.17      0.10     0.09     0.07      NaN  \n",
       "9      0.18     0.05     0.19      0.13     0.13     0.17      NaN  \n",
       "10     0.17     0.02     0.17      0.10     0.11     0.05      NaN  \n",
       "11     0.12     0.01     0.14      0.09     0.12     0.02      NaN  \n",
       "12     0.13     0.05     0.15      0.11     0.06     0.06      NaN  \n",
       "13     0.09     0.05     0.14      0.11     0.09     0.05      NaN  \n",
       "14     0.12     0.06     0.19      0.11     0.13     0.10      NaN  \n",
       "15     0.13     0.12     0.12      0.14     0.07     0.10      NaN  \n",
       "16     0.13     0.02     0.17      0.14     0.05     0.06      NaN  \n",
       "17     0.16     0.08     0.14      0.11     0.07     0.04      NaN  \n",
       "18     0.14     0.07     0.14      0.07     0.14     0.11      NaN  \n",
       "19     0.12     0.13     0.19      0.14     0.04     0.09      NaN  \n",
       "20     0.15     0.08     0.15      0.15     0.11     0.12      NaN  \n",
       "21     0.11     0.03     0.11      0.06     0.09     0.05      NaN  \n",
       "22     0.10      NaN     0.11      0.11     0.07     0.02      NaN  \n",
       "23     0.15     0.16     0.14      0.10     0.10     0.10      NaN  \n",
       "24     0.10     0.05     0.15      0.11     0.10     0.05      NaN  \n",
       "25     0.12     0.05     0.13      0.10     0.10     0.03      NaN  \n",
       "26     0.06     0.06     0.12      0.12     0.06     0.01      NaN  \n",
       "27     0.16     0.05     0.15      0.10     0.11     0.05      NaN  \n",
       "28     0.13     0.06     0.16      0.09     0.12     0.08      NaN  \n",
       "29     0.09     0.01     0.11      0.15     0.07     0.07      NaN  \n",
       "30     0.08     0.05     0.10      0.15     0.10     0.15      NaN  \n",
       "31     0.09     0.04     0.13      0.13     0.08     0.03      NaN  \n",
       "32     0.09     0.05     0.14      0.13     0.08     0.04      NaN  \n",
       "33     0.11     0.03     0.13      0.11     0.11     0.02      NaN  \n",
       "\n",
       "[34 rows x 165 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is where you can copy/paste the above function, and modify it for your specific reference.\n",
    "\n",
    "def load_cayrel2004(io=None):\n",
    "    \"\"\"\n",
    "    Load the Author et al. YYYYx data for the <grouping or classification of stars>.\n",
    "\n",
    "    Table 1 - Observations\n",
    "    Table 2 - Stellar Parameters\n",
    "    Table 3 - Abundance Table\n",
    "    \"\"\"\n",
    "\n",
    "    ## Read in the data tables\n",
    "    obs_df = pd.read_csv('/Users/ayelland/Research/metal-poor-stars/spag/spag/data_templates/cayrel2004/table2.csv', comment=\"#\", na_values=[\"\", \" \", \"nan\", \"NaN\", \"N/A\", \"n/a\"])\n",
    "    param_df = pd.read_csv(\"/Users/ayelland/Research/metal-poor-stars/spag/spag/data_templates/cayrel2004/table4.csv\", comment=\"#\", na_values=[\"\", \" \", \"nan\", \"NaN\", \"N/A\", \"n/a\"])\n",
    "    abund_df = pd.read_csv(\"/Users/ayelland/Research/metal-poor-stars/spag/spag/data_templates/cayrel2004/table8.csv\", comment=\"#\", na_values=[\"\", \" \", \"nan\", \"NaN\", \"N/A\", \"n/a\"])\n",
    "\n",
    "    ## Make the new column names\n",
    "    species = []\n",
    "    for ion in abund_df[\"Species\"].unique():\n",
    "        species_i = ion_to_species(ion)\n",
    "        elem_i = ion_to_element(ion)\n",
    "        if species_i not in species:\n",
    "            species.append(species_i)\n",
    "\n",
    "    epscols = [make_epscol(s) for s in species]\n",
    "    ulcols = [make_ulcol(s) for s in species]\n",
    "    XHcols = [make_XHcol(s).replace(\" \", \"\") for s in species]\n",
    "    ulXHcols = ['ul' + col for col in XHcols]\n",
    "    XFecols = [make_XFecol(s).replace(\" \", \"\") for s in species]\n",
    "    ulXFecols = ['ul' + col for col in XFecols]\n",
    "    errcols = [make_errcol(s) for s in species]\n",
    "\n",
    "    ## New dataframe with proper columns\n",
    "    cayrel2004_df = pd.DataFrame(\n",
    "                    columns=['I/O','Name','Simbad_Identifier','Reference','Ref','Loc','System','RA_hms','RA_deg','DEC_dms','DEC_deg',\n",
    "                    'Teff','logg','Fe/H','Vmic'] + epscols + ulcols + XHcols + ulXHcols + XFecols \n",
    "                    + ulXFecols + errcols)\n",
    "    for i, name in enumerate(abund_df['Name'].unique()):\n",
    "        cayrel2004_df.loc[i,'Name'] = name\n",
    "        # cayrel2004_df.loc[i,'Simbad_Identifier'] = obs_df.loc[obs_df['Name'] == name, 'Simbad_Identifier'].values[0]\n",
    "        cayrel2004_df.loc[i,'Reference'] = 'Author+YYYYx'\n",
    "        cayrel2004_df.loc[i,'Ref'] = 'AUTYYx'\n",
    "        cayrel2004_df.loc[i,'I/O'] = 1\n",
    "        cayrel2004_df.loc[i,'Loc'] = 'UF' # [HA, BU, DS, DW, UF, GC]\n",
    "        # cayrel2004_df.loc[i,'System'] = obs_df.loc[obs_df['Name'] == name, 'System'].values[0]\n",
    "        cayrel2004_df.loc[i,'RA_hms'] = obs_df.loc[obs_df['Name'] == name, 'RA_hms'].values[0]\n",
    "        cayrel2004_df.loc[i,'RA_deg'] = coord.ra_hms_to_deg(cayrel2004_df.loc[i,'RA_hms'], precision=6)\n",
    "        cayrel2004_df.loc[i,'DEC_dms'] = obs_df.loc[obs_df['Name'] == name, 'DEC_dms'].values[0]\n",
    "        cayrel2004_df.loc[i,'DEC_deg'] = coord.dec_dms_to_deg(cayrel2004_df.loc[i,'DEC_dms'], precision=2)\n",
    "        cayrel2004_df.loc[i,'Teff'] = param_df.loc[param_df['Name'] == name, 'Teff'].values[0]\n",
    "        cayrel2004_df.loc[i,'logg'] = param_df.loc[param_df['Name'] == name, 'logg'].values[0]\n",
    "        cayrel2004_df.loc[i,'Fe/H'] = param_df.loc[param_df['Name'] == name, 'Fe/H_m'].values[0]\n",
    "        cayrel2004_df.loc[i,'Vmic'] = param_df.loc[param_df['Name'] == name, 'Vmic'].values[0]\n",
    "\n",
    "        ## Fill in data\n",
    "        star_df = abund_df[abund_df['Name'] == name]\n",
    "        for j, row in star_df.iterrows():\n",
    "            ion = row[\"Species\"]\n",
    "            species_i = ion_to_species(ion)\n",
    "            elem_i = ion_to_element(ion)\n",
    "\n",
    "            logepsX_sun_a09 = get_solar(elem_i, version='asplund2009')[0]\n",
    "            logepsFe_a09 = star_df.loc[star_df['Species'] == 'Fe I', 'logepsX'].values[0]\n",
    "            feh_a09 = logepsFe_a09 - get_solar('Fe', version='asplund2009')[0]\n",
    "\n",
    "            ## Assign epsX values\n",
    "            col = make_epscol(species_i)\n",
    "            if col in epscols:\n",
    "                cayrel2004_df.loc[i, col] = row[\"logepsX\"] if pd.isna(row[\"l_logepsX\"]) else np.nan\n",
    "\n",
    "            ## Assign ulX values\n",
    "            col = make_ulcol(species_i)\n",
    "            if col in ulcols:\n",
    "                cayrel2004_df.loc[i, col] = row[\"logepsX\"] if pd.notna(row[\"l_logepsX\"]) else np.nan\n",
    "\n",
    "            ## Assign [X/H] and ul[X/H]values\n",
    "            col = make_XHcol(species_i).replace(\" \", \"\")\n",
    "            if col in XHcols:\n",
    "                if pd.isna(row[\"l_[X/H]\"]):\n",
    "                    cayrel2004_df.loc[i, col] = normal_round(row[\"logepsX\"] - logepsX_sun_a09, 2)\n",
    "                    cayrel2004_df.loc[i, 'ul'+col] = np.nan\n",
    "                else:\n",
    "                    cayrel2004_df.loc[i, col] = np.nan\n",
    "                    cayrel2004_df.loc[i, 'ul'+col] = normal_round(row[\"logepsX\"] - logepsX_sun_a09, 2)\n",
    "                if 'e_[X/H]' in row.index:\n",
    "                    cayrel2004_df.loc[i, 'e_'+col] = row[\"e_[X/H]\"]\n",
    "\n",
    "            ## Assign [X/Fe] values\n",
    "            col = make_XFecol(species_i).replace(\" \", \"\")\n",
    "            if col in XFecols:\n",
    "                if pd.isna(row[\"l_[X/Fe]\"]):\n",
    "                    cayrel2004_df.loc[i, col] = normal_round((row[\"logepsX\"] - logepsX_sun_a09) - feh_a09, 2)\n",
    "                    cayrel2004_df.loc[i, 'ul'+col] = np.nan\n",
    "                else:\n",
    "                    cayrel2004_df.loc[i, col] = np.nan\n",
    "                    cayrel2004_df.loc[i, 'ul'+col] = normal_round((row[\"logepsX\"] - logepsX_sun_a09) - feh_a09, 2)\n",
    "                if 'e_[X/Fe]' in row.index:\n",
    "                    cayrel2004_df.loc[i, 'e_'+col] = row[\"e_[X/Fe]\"]\n",
    "\n",
    "            ## Assign error values\n",
    "            col = make_errcol(species_i)\n",
    "            if col in errcols:\n",
    "                e_logepsX = row.get(\"e_logepsX\", np.nan)\n",
    "                if pd.notna(e_logepsX):\n",
    "                    cayrel2004_df.loc[i, col] = e_logepsX\n",
    "                else:\n",
    "                    cayrel2004_df.loc[i, col] = np.nan\n",
    "\n",
    "    ## Drop the Fe/Fe columns\n",
    "    cayrel2004_df.drop(columns=['[Fe/Fe]','ul[Fe/Fe]','[FeII/Fe]','ul[FeII/Fe]'], inplace=True, errors='ignore')\n",
    "\n",
    "    return cayrel2004_df\n",
    "\n",
    "df = load_cayrel2004()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20663730",
   "metadata": {},
   "source": [
    "---\n",
    "## Helpful Conversion Scripts for Different Datafiles & Numbers\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ce3c2",
   "metadata": {},
   "source": [
    "### Abundance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd4e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logeps(Fe):  1.88\n",
      "logeps(Sr): <-3.90\n",
      "logeps(Ba):  -3.50\n",
      "[Fe/H]:      -5.62\n",
      "[Sr/H]:     <-6.77\n",
      "[Ba/H]:      -5.68\n",
      "[Sr/Fe]:    <-1.15\n",
      "[Ba/Fe]:     -0.06\n"
     ]
    }
   ],
   "source": [
    "## Quick Abundance Conversions\n",
    "\n",
    "### Solar Abundances\n",
    "epsfe_sun = rd.get_solar('Fe')[0]\n",
    "epsba_sun = rd.get_solar('Ba')[0]\n",
    "epssr_sun = rd.get_solar('Sr')[0]\n",
    "\n",
    "### From Anna's notes of a presentation\n",
    "srfe = -1.15\n",
    "epsba = -3.5\n",
    "feh = -5.62\n",
    "\n",
    "### Calculated log(eps) values\n",
    "srh = srfe + feh\n",
    "epssr = epssr_sun + srh\n",
    "epsfe = epsfe_sun + feh\n",
    "\n",
    "feh_new = epsfe - epsfe_sun\n",
    "srh_new = epssr - epssr_sun\n",
    "bah_new = epsba - epsba_sun\n",
    "\n",
    "srfe_new = srh_new - feh_new\n",
    "bafe_new = bah_new - feh_new\n",
    "\n",
    "print(f\"logeps(Fe):  {epsfe:.2f}\")\n",
    "print(f\"logeps(Sr): <{epssr:.2f}\")\n",
    "print(f\"logeps(Ba):  {epsba:.2f}\")\n",
    "print(f\"[Fe/H]:      {feh_new:.2f}\")\n",
    "print(f\"[Sr/H]:     <{srh_new:.2f}\")\n",
    "print(f\"[Ba/H]:      {bah_new:.2f}\")\n",
    "print(f\"[Sr/Fe]:    <{srfe_new:.2f}\")\n",
    "print(f\"[Ba/Fe]:     {bafe_new:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167a4fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XH_from_eps(0.73, 'Sr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac193c",
   "metadata": {},
   "source": [
    "### CDS $\\rightarrow$ CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert all CDS Standard Formatted Tables to CSVs for Stellar Abundances\n",
    "create_csv_files = True\n",
    "if create_csv_files:\n",
    "    system =  'cayrel2004'\n",
    "    table_numbers = [2,3,8]\n",
    "    for n in table_numbers:\n",
    "\n",
    "        base_path = f\"/Users/ayelland/Research/metal-poor-stars/spag/spag/data_templates/cayrel2004/\"\n",
    "        table_path = base_path + f\"table{n}.dat\"\n",
    "        readme_path = base_path + f\"ReadMe\"\n",
    "        csv_path = base_path + f\"table{n}.csv\"\n",
    "\n",
    "        if os.path.exists(table_path) and os.path.exists(readme_path):\n",
    "            table_data = ascii.read(table_path, format='cds', readme=readme_path)\n",
    "                    # guess=False,\n",
    "                    # fast_reader=False\n",
    "                    \n",
    "            table_data = table_data.to_pandas()\n",
    "            table_data.to_csv(csv_path, index=False)\n",
    "        else:\n",
    "            print(f\"Table {n} or ReadMe file does not exist for {system}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Converted table1 to CSV.\n",
      " Failed to read table2: Column V(MW) failed to convert: invalid literal for int() with base 10: 'nan'\n",
      " Converted table3 to CSV.\n",
      " Converted table4 to CSV.\n",
      " Converted table5 to CSV.\n"
     ]
    }
   ],
   "source": [
    "## Convert CDS Standard Formatted Tables to CSVs for Galaxy Properties\n",
    "\n",
    "from astropy.io import ascii\n",
    "import os\n",
    "\n",
    "create_csv_files = True\n",
    "if create_csv_files:\n",
    "    system = 'mcconnachie2012'\n",
    "    table_numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "    base_path = f\"/Users/ayelland/Research/metal-poor-stars/spag/spag/data/galaxy_properties/{system}/\"\n",
    "    readme_path = os.path.join(base_path, \"ReadMe\")\n",
    "\n",
    "    for n in table_numbers:\n",
    "        table_path = os.path.join(base_path, f\"table{n}.dat\")\n",
    "        csv_path = os.path.join(base_path, f\"table{n}.csv\")\n",
    "\n",
    "        if os.path.exists(table_path) and os.path.exists(readme_path):\n",
    "            try:\n",
    "                table_data = ascii.read(\n",
    "                    table_path,\n",
    "                    format='cds',\n",
    "                    readme=readme_path,\n",
    "                    guess=False,\n",
    "                    fast_reader=False,\n",
    "                    fill_values=[('-', 'nan'), ('--', 'nan'), ('...', 'nan')]\n",
    "                )\n",
    "                table_data = table_data.to_pandas()\n",
    "                table_data.to_csv(csv_path, index=False)\n",
    "                print(f\" Converted table{n} to CSV.\")\n",
    "            except Exception as e:\n",
    "                print(f\" Failed to read table{n}: {e}\")\n",
    "        else:\n",
    "            print(f\"  Missing table{n}.dat or ReadMe file for {system}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d0f7b",
   "metadata": {},
   "source": [
    "### HMS/DMS $\\leftrightarrow$ Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f17dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Coordinates:\n",
      "\n",
      "(16:10:32.30 , -08:15:38.50)\n",
      "(15:05:02.13 , -13:44:20.23)\n",
      "(18:09:43.61 , -40:52:07.99)\n"
     ]
    }
   ],
   "source": [
    "## Convert coordinates between degrees and hms/dms format\n",
    "\n",
    "data = '''\n",
    "242.63458901020093, -8.260693273003724 \n",
    "226.25888112673744, -13.738953843436517\n",
    "272.43169186461097, -40.86888561990257 \n",
    "'''\n",
    "\n",
    "def convert_deg_to_hmsdms(data):\n",
    "    \"\"\"\n",
    "    Convert the given data string of coordinates from degrees to hms/dms format.\n",
    "    \"\"\"\n",
    "    coords = []\n",
    "    for line in data.strip().split('\\n'):\n",
    "        ra_deg, dec_deg = map(float, line.split(','))\n",
    "        ra_hms = coord.ra_deg_to_hms(ra_deg, precision=2)\n",
    "        dec_dms = coord.dec_deg_to_dms(dec_deg, precision=2)\n",
    "        coords.append((ra_hms, dec_dms))\n",
    "        # print(f\"{ra_hms}, {dec_dms}\")\n",
    "    return coords\n",
    "\n",
    "def convert_hmsdms_to_deg(data):\n",
    "    \"\"\"\n",
    "    Convert the given data string of coordinates from degrees to hms/dms format.\n",
    "    \"\"\"\n",
    "    coords = []\n",
    "    for line in data.strip().split('\\n'):\n",
    "        ra_hms, dec_hms = map(str, line.split(','))\n",
    "        ra_deg = coord.ra_hms_to_deg(ra_hms, precision=6)\n",
    "        dec_deg = coord.dec_dms_to_deg(dec_hms, precision=6)\n",
    "        coords.append((ra_deg, dec_deg))\n",
    "        # print(f\"{ra_deg}, {dec_deg}\")\n",
    "\n",
    "    return coords\n",
    "\n",
    "# Convert the coordinates\n",
    "try:\n",
    "    txt = convert_deg_to_hmsdms(data)\n",
    "except:\n",
    "    try:\n",
    "        txt = convert_hmsdms_to_deg(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting coordinates: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "print(\"Converted Coordinates:\\n\")\n",
    "for c in txt:\n",
    "    print(f'({c[0]} , {c[1]})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
